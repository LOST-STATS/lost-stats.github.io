
<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">
    <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script>
  <script type="text/javascript" src="/assets/js/just-the-docs.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Penalized Regression | LOST</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Penalized Regression" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="LOST" />
<script type="application/ld+json">
{"@type":"WebPage","headline":"Penalized Regression","url":"/Machine_Learning/penalized_regression.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML">
  </script>
</head>
<body>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
      <title>Link</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
        <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
      </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
      <title>Search</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
        <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
      </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
      <title>Menu</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
        <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
      </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
      <title>Expand</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
        <polyline points="9 18 15 12 9 6"></polyline>
      </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
      <title>Document</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
        <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
      </svg>
    </symbol>
  </svg>
  <div class="side-bar">
    <div class="site-header">
      <a href="/" class="site-title lh-tight">
  LOST
</a>
      <a href="#" id="menu-button" class="site-button">
        <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
      </a>
    </div>
    <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
      <ul class="nav-list"><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/data_manipulation.html" class="nav-list-link">Data Manipulation</a><ul class="nav-list "><li class="nav-list-item "><a href="/Data_Manipulation/Regular_Expressions.html" class="nav-list-link">Regular Expressions</a></li><li class="nav-list-item "><a href="/Data_Manipulation/collapse_a_data_set.html" class="nav-list-link">Collapse a Data Set</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/Combining_Datasets/combining_datasets_overview.html" class="nav-list-link">Combining Datasets</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Combining_Datasets/combining_datasets_vertical_combination.html" class="nav-list-link">Vertical Combination</a>
                      </li><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Combining_Datasets/combining_datasets_horizontal_merge_deterministic.html" class="nav-list-link">Horizontal Combination (Deterministic)</a>
                      </li></ul></li><li class="nav-list-item "><a href="/Data_Manipulation/creating_a_variable_with_group_calculations.html" class="nav-list-link">Creating a Variable with Group Calculations</a></li><li class="nav-list-item "><a href="/Data_Manipulation/creating_categorical_variables.html" class="nav-list-link">Creating Categorical Variables</a></li><li class="nav-list-item "><a href="/Data_Manipulation/Creating_Dummy_Variables/creating_dummy_variables.html" class="nav-list-link">Creating Dummy Variables</a></li><li class="nav-list-item "><a href="/Data_Manipulation/determine_the_observation_level_of_a_data_set.html" class="nav-list-link">Determine the Observation Level of a Data Set</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/Reshaping/reshape.html" class="nav-list-link">Reshaping Data</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_wide_to_long.html" class="nav-list-link">Reshape Panel Data from Wide to Long</a>
                      </li><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_long_to_wide.html" class="nav-list-link">Reshape Panel Data from Long to Wide</a>
                      </li></ul></li><li class="nav-list-item "><a href="/Data_Manipulation/rowwise_calculations.html" class="nav-list-link">Rowwise Calculations</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Geo-Spatial/Geo-spatial.html" class="nav-list-link">Geo-Spatial</a><ul class="nav-list "><li class="nav-list-item "><a href="/Geo-Spatial/choropleths.html" class="nav-list-link">Choropleths</a></li><li class="nav-list-item "><a href="/Geo-Spatial/geocoding.html" class="nav-list-link">Geocoding</a></li><li class="nav-list-item "><a href="/Geo-Spatial/handling_raster_data.html" class="nav-list-link">Handling Raster Data</a></li><li class="nav-list-item "><a href="/Geo-Spatial/merging_shape_files.html" class="nav-list-link">Merging Shape Files</a></li><li class="nav-list-item "><a href="/Geo-Spatial/spatial_joins.html" class="nav-list-link">Spatial Joins</a></li><li class="nav-list-item "><a href="/Geo-Spatial/spatial_lag_model.html" class="nav-list-link">Spatial Lag Model</a></li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Machine_Learning/Machine_Learning.html" class="nav-list-link">Machine Learning</a><ul class="nav-list "><li class="nav-list-item "><a href="/Machine_Learning/Nearest_Neighbor.html" class="nav-list-link">K-Nearest Neighbor Matching</a></li><li class="nav-list-item "><a href="/Machine_Learning/artificial_neural_network.html" class="nav-list-link">Artificial Neural Network</a></li><li class="nav-list-item "><a href="/Machine_Learning/boosted_regression_trees.html" class="nav-list-link">Boosted Regression Trees</a></li><li class="nav-list-item "><a href="/Machine_Learning/causal_forest.html" class="nav-list-link">Causal Forest</a></li><li class="nav-list-item "><a href="/Machine_Learning/decision_trees.html" class="nav-list-link">Decision Trees</a></li><li class="nav-list-item  active"><a href="/Machine_Learning/penalized_regression.html" class="nav-list-link active">Penalized Regression</a></li><li class="nav-list-item "><a href="/Machine_Learning/random_forest.html" class="nav-list-link">Random Forest</a></li><li class="nav-list-item "><a href="/Machine_Learning/support_vector_machine.html" class="nav-list-link">Support Vector Machine</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Model_Estimation.html" class="nav-list-link">Model Estimation</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/OLS/OLS.html" class="nav-list-link">Ordinary Least Squares</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/ANOVA.html" class="nav-list-link">ANOVA</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/simple_linear_regression.html" class="nav-list-link">Simple Linear Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/stepwise_regression.html" class="nav-list-link">Stepwise Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/interaction_terms_and_polynomials.html" class="nav-list-link">Interaction Terms and Polynomials</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/fixed_effects_in_linear_regression.html" class="nav-list-link">Fixed Effects in Linear Regression</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Matching/matching.html" class="nav-list-link">Matching</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Matching/entropy_balancing.html" class="nav-list-link">Entropy Balancing</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Matching/propensity_score_matching.html" class="nav-list-link">Propensity Score Matching</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/GLS/GLS.html" class="nav-list-link">Generalised Least Squares</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/gmm.html" class="nav-list-link">Generalized Method of Moments</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/heckman_correction_model.html" class="nav-list-link">Heckman Correction Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/logit_model.html" class="nav-list-link">Logit Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/mcfaddens_choice_model.html" class="nav-list-link">McFadden's Choice Model (Alternative-Specific Conditional Logit)</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/ordered_probit_logit.html" class="nav-list-link">Ordered Probit/Logit</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/probit_model.html" class="nav-list-link">Probit Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/tobit.html" class="nav-list-link">Tobit Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/quantile_regression.html" class="nav-list-link">Quantile Regression</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Multilevel_Models/Multilevel_Models.html" class="nav-list-link">Multilevel Models</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Multilevel_Models/linear_mixed_effects_regression.html" class="nav-list-link">Linear Mixed-Effects Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Multilevel_Models/mixed_logit.html" class="nav-list-link">Mixed Logit Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Multilevel_Models/random_mixed_effects_estimation.html" class="nav-list-link">Random/Mixed Effects in Linear Regression</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Research_Design/Research_Design.html" class="nav-list-link">Research Design</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/density_discontinuity_test.html" class="nav-list-link">Density Discontinuity Tests for Regression Discontinuity</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/event_study.html" class="nav-list-link">Difference in Differences Event Study</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/instrumental_variables.html" class="nav-list-link">Instrumental Variables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/regression_discontinuity_design.html" class="nav-list-link">Regression Discontinuity Design</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/synthetic_control_method.html" class="nav-list-link">Synthetic Control</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/two_by_two_difference_in_difference.html" class="nav-list-link">2x2 Difference in Difference</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Statistical_Inference/Statistical_Inference.html" class="nav-list-link">Statistical Inference</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/Marginal_Effects_in_Nonlinear_Regression.html" class="nav-list-link">Marginal Effects in Nonlinear Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/linear_hypothesis_tests.html" class="nav-list-link">Linear Hypothesis Tests</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/nonlinear_hypothesis_tests.html" class="nav-list-link">Nonlinear Hypothesis Tests</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/nonstandard_errors.html" class="nav-list-link">Nonstandard Errors</a>
                      </li></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Presentation.html" class="nav-list-link">Presentation</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Figures/Figures.html" class="nav-list-link">Figures</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Adding_and_Labeling_a_Reference_Line.html" class="nav-list-link">Adding and Labeling a Reference Line</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Animated_graphs.html" class="nav-list-link">Animated Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Scatterplots.html" class="nav-list-link">Scatterplots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Styling_Scatterplots.html" class="nav-list-link">Styling Scatterplots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/bar_graphs.html" class="nav-list-link">Bar Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/binscatter.html" class="nav-list-link">Binned Scatterplots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/color_palettes.html" class="nav-list-link">Color Palettes</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/density_plots.html" class="nav-list-link">Density Plots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/faceted_graphs.html" class="nav-list-link">Faceted Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/formatting_graph_axes.html" class="nav-list-link">Formatting Graph Axes</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/formatting_graph_legends.html" class="nav-list-link">Formatting Graph Legends</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/graph_themes.html" class="nav-list-link">Graph Themes</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/heatmap_colored_correlation_matrix.html" class="nav-list-link">Heatmap Colored Correlation Matrix</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/histograms.html" class="nav-list-link">Histograms</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/line_graph_with_labels_at_the_beginning_or_end.html" class="nav-list-link">Line Graph with Labels at the Beginning or End of Lines</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/line_graphs.html" class="nav-list-link">Line Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/marginal_effects_plots_for_interactions_with_categorical_variables.html" class="nav-list-link">Marginal effects plots for interactions with categorical variables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/marginal_effects_plots_for_interactions_with_continuous_variables.html" class="nav-list-link">Marginal Effects Plots for Interactions with Continuous Variables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/sankey_diagrams.html" class="nav-list-link">Sankey Diagrams</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/scatterplot_by_group_on_shared_axes.html" class="nav-list-link">Scatterplot by Group on Shared Axes</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/styling_line_graphs.html" class="nav-list-link">Styling Line Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/summary_graphs.html" class="nav-list-link">Graphing a By-Group or Over-Time Summary Statistic</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Tables/Tables.html" class="nav-list-link">Tables</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Balance_Tables.html" class="nav-list-link">Balance Tables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Correlation_Matrix.html" class="nav-list-link">Correlation Matrix</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Cross-Tabulation.html" class="nav-list-link">Cross-Tabulation</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Custom_Tables.html" class="nav-list-link">Building Custom Tables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Regression_Tables.html" class="nav-list-link">Regression Tables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Summary_Statistics_Tables.html" class="nav-list-link">Summary Statistics Tables</a>
                      </li></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Time_Series/Time_Series.html" class="nav-list-link">Time Series</a><ul class="nav-list "><li class="nav-list-item "><a href="/Time_Series/AR-models.html" class="nav-list-link">AR Models</a></li><li class="nav-list-item "><a href="/Time_Series/ARCH_Model.html" class="nav-list-link">ARCH Model</a></li><li class="nav-list-item "><a href="/Time_Series/ARIMA-models.html" class="nav-list-link">ARIMA Models</a></li><li class="nav-list-item "><a href="/Time_Series/ARMA-models.html" class="nav-list-link">ARMA Models</a></li><li class="nav-list-item "><a href="/Time_Series/Autocorrelation_Function.html" class="nav-list-link">Autocorrelation Function</a></li><li class="nav-list-item "><a href="/Time_Series/GARCH_Model.html" class="nav-list-link">GARCH Model</a></li><li class="nav-list-item "><a href="/Time_Series/Granger_Causality.html" class="nav-list-link">Granger Causality</a></li><li class="nav-list-item "><a href="/Time_Series/MA_Model.html" class="nav-list-link">MA Models</a></li><li class="nav-list-item "><a href="/Time_Series/Rolling_Regression.html" class="nav-list-link">Rolling Regression</a></li><li class="nav-list-item "><a href="/Time_Series/State_Space_Models.html" class="nav-list-link">State Space Models</a></li><li class="nav-list-item "><a href="/Time_Series/VAR-models.html" class="nav-list-link">VAR Models</a></li><li class="nav-list-item "><a href="/Time_Series/creating_time_series_dataset.html" class="nav-list-link">Creating a Time Series Dataset</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Other/Other.html" class="nav-list-link">Other</a><ul class="nav-list "><li class="nav-list-item "><a href="/Other/create_a_conda_package.html" class="nav-list-link">Create a Conda Package (Python)</a></li><li class="nav-list-item "><a href="/Other/get_a_list_of_files.html" class="nav-list-link">Get a List of Files</a></li><li class="nav-list-item "><a href="/Other/import_a_foreign_data_file.html" class="nav-list-link">Import a Foreign Data File</a></li><li class="nav-list-item "><a href="/Other/importing_delimited_files.html" class="nav-list-link">Import a Delimited Data File (CSV, TSV)</a></li><li class="nav-list-item "><a href="/Other/set_a_working_directory.html" class="nav-list-link">Set a Working Directory</a></li><li class="nav-list-item "><a href="/Other/simple_web_scrape.html" class="nav-list-link">Simple Web Scraping</a></li><li class="nav-list-item "><a href="/Other/task_scheduling_with_github_actions.html" class="nav-list-link">Task Scheduling with Github Actions</a></li></ul></li><li class="nav-list-item"><a href="/Desired_Nonexistent_Pages/desired_nonexistent_pages.html" class="nav-list-link">Desired Nonexistent Pages</a></li><li class="nav-list-item"><a href="/Contributing/Contributing.html" class="nav-list-link">Contributing</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul>
    </nav>
    <footer class="site-footer">
      This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  </div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
        <div class="search">
          <div class="search-input-wrap">
            <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search LOST" aria-label="Search LOST" autocomplete="off">
            <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
          </div>
          <div id="search-results" class="search-results"></div>
        </div>
    </div>
    <div id="main-content-wrap" class="main-content-wrap">
          <nav aria-label="Breadcrumb" class="breadcrumb-nav">
            <ol class="breadcrumb-nav-list">
                <li class="breadcrumb-nav-list-item"><a href="/Machine_Learning/Machine_Learning.html">Machine Learning</a></li>
              <li class="breadcrumb-nav-list-item"><span>Penalized Regression</span></li>
            </ol>
          </nav>
      <div id="main-content" class="main-content" role="main">
          <h1 id="penalized-regression">
          <a href="#penalized-regression" aria-labelledby="penalized-regression" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Penalized Regression
      </h1>
<p>When running a regression, especially one with many predictors, the results have a tendency to overfit the data, reducing out-of-sample predictive properties.</p>
<p>Penalized regression eases this problem by forcing the regression estimator to shrink its coefficients towards 0 in order to avoid the “penalty” term imposed on the coefficients. This process is closely related to the idea of Bayesian shrinkage, and indeed standard penalized regression results are equivalent to regression performed using <a href="https://amstat.tandfonline.com/doi/abs/10.1198/016214508000000337?casa_token=DE6O93Bz7uUAAAAA:Ff_MiPXvPH32NA2hnGtZtqb8grXEiEqF0fdO3B0p_a6wOaqRciCZ4ASwxn69gdOb93Lbt-HSyK1o4As">certain Bayesian priors</a>.</p>
<p>Regular OLS selects coefficients \(\hat{\beta}\) to minimize the sum of squared errors:</p>
\[\min\sum_i(y_i - X_i\hat{\beta})^2\]
<p>Non-OLS regressions similarly select coefficients to minimize a similar objective function. Penalized regression adds a penalty term \(\lambda\lVert\beta\rVert_p\) to that objective function, where \(\lambda\) is a tuning parameter that determines how harshly to penalize coefficients, and \(\lVert\beta\rVert_p\) is the \(p\)-norm of the coefficients, or \(\sum_j\lvert\beta\rvert^p\).</p>
\[\min\left(\sum_i(y_i - X_i\hat{\beta})^2 + \lambda\left\lVert\beta\right\rVert_p \right)\]
<p>Typically \(p\) is set to 1 for LASSO regression (least absolute shrinkage and selection operator), which has the effect of tending to set coefficients to 0, i.e. model selection, or to 2 for Ridge Regression. Elastic net regression provides a weighted mix of LASSO and Ridge penalties, commonly referring to the weight as \(\alpha\).</p>
      <h2 id="keep-in-mind">
          <a href="#keep-in-mind" aria-labelledby="keep-in-mind" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Keep in Mind
      </h2>
<ul>
  <li>To avoid being penalized for a constant term, or by differences in scale between variables, it is a very good idea to standardize each variable (subtract the mean and divide by the standard deviation) before running a penalized regression.</li>
  <li>Penalized regression can be run for logit and other kinds of regression, not just linear regression. Using penalties with general linear models like logit is common.</li>
  <li>Penalized regression coefficients are designed to improve out-of-sample prediction, but they are biased. If the goal is estimation of a parameter, rather than prediction, this should be kept in mind. A common procedure is to use LASSO to select variables, and then run regular regression models with the variables that LASSO has selected.</li>
  <li>The \(\lambda\) parameter is often chosen using cross-validation. Many penalized regression commands include an option to select \(\lambda\) by cross-validation automatically.</li>
  <li>LASSO models commonly include variables along with polynomial transformation of those variables and interactions, allowing LASSO to determine which transformations are worth keeping.</li>
</ul>
      <h2 id="also-consider">
          <a href="#also-consider" aria-labelledby="also-consider" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Also Consider
      </h2>
<ul>
  <li>If it is not important to estimate coefficients but the goal is simply to predict an outcome, then there are many other <a href="/Machine_Learning/Machine_Learning.html">machine learning</a> methods that do so, and in some cases can handle higher dimensionality or work with smaller samples.</li>
</ul>
      <h1 id="implementations">
          <a href="#implementations" aria-labelledby="implementations" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementations
      </h1>
      <h2 id="python">
          <a href="#python" aria-labelledby="python" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Python
      </h2>
<p>This is an example of running penalised regressions in Python. The main takeaways are that the ubiquitous machine learning package <a href="https://scikit-learn.org/stable/index.html"><strong>sklearn</strong></a> can perform lasso, ridge, and elastic net regressions. In the example below, we’ll see all three in action. The level of penalisation will be set automatically by cross-validation, although a user may also supply the number directly.</p>
<p>This example will use the seaborn package (for data), the patsy package (to create matrices from formulae), the matplotlib package (for plotting), the pandas package (for data manipulation), and the <a href="https://scikit-learn.org/stable/index.html"><strong>sklearn</strong></a> package (for machine learning). To run the example below, you may need to first install these packages. First, we need to import these packages for use.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span><span class="p">,</span> <span class="n">dmatrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span><span class="p">,</span> <span class="n">ElasticNetCV</span><span class="p">,</span> <span class="n">RidgeCV</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
</code></pre></div></div>
<p>Now let’s load the data and transform it into a vector of endogeneous variables, and a matrix of exogenous variables. Using patsy, we’ll ask for all interaction variables among sepal width, petal length, and petal width (and exclude having an intercept).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s">"iris"</span><span class="p">)</span>
<span class="n">formula</span> <span class="o">=</span> <span class="p">(</span><span class="s">"sepal_length ~ (sepal_width + petal_length + petal_width)**2 - 1"</span><span class="p">)</span>
<span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">iris</span><span class="p">)</span>
</code></pre></div></div>
<p>Some machine learning algorithms are more performant with data that are scaled before being used. One should be careful when scaling data if using test and training sets; here, we’re not worried about a test set though, so we just use the standard scaler (which transforms data to have 0 mean and unit standard deviation) on all of the \(X\) and \(y\) data.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scale_X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">scale_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">scale_y</span> <span class="o">=</span> <span class="n">scale_y</span><span class="p">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># ravel collapses a (150, 1) vector to (150,)
</span></code></pre></div></div>
<p>Now we run lasso with cross-validation.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg_lasso</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">scale_X</span><span class="p">,</span> <span class="n">scale_y</span><span class="p">)</span>
</code></pre></div></div>
<p>Let’s display the results so we can see for which value of \(\alpha\) the lowest mean squared error occurred. Note that sklearn uses the convention that \(\alpha\) (rather than \(\lambda\)) is the shrinkage parameter.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">1e-4</span>  <span class="c1"># This is to avoid division by zero while taking the base 10 logarithm
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">reg_lasso</span><span class="p">.</span><span class="n">alphas_</span> <span class="o">+</span> <span class="n">EPSILON</span><span class="p">,</span> <span class="n">reg_lasso</span><span class="p">.</span><span class="n">mse_path_</span><span class="p">,</span> <span class="s">':'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reg_lasso</span><span class="p">.</span><span class="n">alphas_</span> <span class="o">+</span> <span class="n">EPSILON</span><span class="p">,</span> <span class="n">reg_lasso</span><span class="p">.</span><span class="n">mse_path_</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="s">'k'</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'Average across the folds'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">reg_lasso</span><span class="p">.</span><span class="n">alpha_</span> <span class="o">+</span> <span class="n">EPSILON</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s">r'$\alpha$: CV estimate'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">r'$\alpha$'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Mean square error'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Mean square error on each fold: coordinate descent '</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'tight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/Machine_Learning/Images/penalised_reg_example_py.png" alt="Finding_alpha_from_CV" /></p>
<p>Let’s look at the coefficients that are selected with this optimal value of \(\alpha\) (which you can access via <code class="language-plaintext highlighter-rouge">reg_lasso.alpha_</code>):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">reg_lasso</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">dmatrix</span><span class="p">(</span><span class="n">formula</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'~'</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">iris</span><span class="p">).</span><span class="n">design_info</span><span class="p">.</span><span class="n">term_names</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">f'Coeff </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> = </span><span class="si">{</span><span class="n">coef</span><span class="p">:.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Coeff sepal_width = 0.36
Coeff petal_length = 1.38
Coeff petal_width = -0.39
Coeff sepal_width:petal_length = -0.00
Coeff sepal_width:petal_width = -0.32
Coeff petal_length:petal_width = 0.33
</code></pre></div></div>
<p>Now let’s see what coefficients we get with ridge regression and elastic net (a mixture between ridge and lasso; here we use the default setting of a half-mixture between the two).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg_elastic</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">scale_X</span><span class="p">,</span> <span class="n">scale_y</span><span class="p">)</span>
<span class="n">reg_ridge</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">scale_X</span><span class="p">,</span> <span class="n">scale_y</span><span class="p">)</span>
<span class="c1"># For convenient comparison, let's pop these into a dataframe
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'Lasso'</span><span class="p">:</span> <span class="n">reg_lasso</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span>
                   <span class="s">'Elastic Net (0.5)'</span><span class="p">:</span> <span class="n">reg_elastic</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span>
                   <span class="s">'Ridge'</span><span class="p">:</span> <span class="n">reg_ridge</span><span class="p">.</span><span class="n">coef_</span><span class="p">},</span>
                  <span class="n">index</span><span class="o">=</span><span class="n">dmatrix</span><span class="p">(</span><span class="n">formula</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'~'</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">iris</span><span class="p">).</span><span class="n">design_info</span><span class="p">.</span><span class="n">term_names</span><span class="p">).</span><span class="n">T</span>
<span class="n">df</span><span class="p">[</span><span class="s">r'$\alpha$'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">reg_lasso</span><span class="p">.</span><span class="n">alpha_</span><span class="p">,</span> <span class="n">reg_elastic</span><span class="p">.</span><span class="n">alpha_</span><span class="p">,</span> <span class="n">reg_ridge</span><span class="p">.</span><span class="n">alpha_</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">T</span>
<span class="n">df</span>
</code></pre></div></div>
<div>
<div class="table-wrapper"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Lasso</th>
      <th>Elastic Net (0.5)</th>
      <th>Ridge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sepal_width</th>
      <td>0.362891</td>
      <td>0.357877</td>
      <td>0.288003</td>
    </tr>
    <tr>
      <th>petal_length</th>
      <td>1.383851</td>
      <td>1.321840</td>
      <td>0.931508</td>
    </tr>
    <tr>
      <th>petal_width</th>
      <td>-0.386780</td>
      <td>-0.320669</td>
      <td>-0.148416</td>
    </tr>
    <tr>
      <th>sepal_width:petal_length</th>
      <td>-0.000000</td>
      <td>0.039810</td>
      <td>0.363751</td>
    </tr>
    <tr>
      <th>sepal_width:petal_width</th>
      <td>-0.322053</td>
      <td>-0.362515</td>
      <td>-0.497244</td>
    </tr>
    <tr>
      <th>petal_length:petal_width</th>
      <td>0.327846</td>
      <td>0.321951</td>
      <td>0.326384</td>
    </tr>
    <tr>
      <th>α</th>
      <td>0.000901</td>
      <td>0.001802</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table></div>
</div>
      <h2 id="r">
          <a href="#r" aria-labelledby="r" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> R
      </h2>
<p>We will use the <strong>glmnet</strong> package.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install glmnet and tidyverse if necessary</span><span class="w">
</span><span class="c1"># install.packages('glmnet', 'tidyverse')</span><span class="w">

</span><span class="c1"># Load glmnet</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span><span class="w">

</span><span class="c1"># Load iris data</span><span class="w">
</span><span class="n">data</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create a matrix with all variables other than our dependent vairable, Sepal.Length</span><span class="w">
</span><span class="c1"># and interactions. </span><span class="w">
</span><span class="c1"># -1 to omit the intercept</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Sepal.Length</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="p">(</span><span class="n">.</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iris</span><span class="p">))</span><span class="w">
</span><span class="c1"># Add squared terms of numeric variables</span><span class="w">
</span><span class="n">numeric.var.names</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">iris</span><span class="p">)[</span><span class="m">2</span><span class="o">:</span><span class="m">4</span><span class="p">]</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">iris</span><span class="p">[,</span><span class="n">numeric.var.names</span><span class="p">]</span><span class="o">^</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">M</span><span class="p">)[</span><span class="m">16</span><span class="o">:</span><span class="m">18</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="n">numeric.var.names</span><span class="p">,</span><span class="s1">'squared'</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create a matrix for our dependent variable too</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.matrix</span><span class="p">(</span><span class="n">iris</span><span class="o">$</span><span class="n">Sepal.Length</span><span class="p">)</span><span class="w">

</span><span class="c1"># Standardize all variables</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scale</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scale</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="w">


</span><span class="c1"># Use glmnet to estimate penalized regression</span><span class="w">
</span><span class="c1"># We pick family = "gaussian" for linear regression;</span><span class="w">
</span><span class="c1"># other families work for other kinds of data, like binomial for binary data</span><span class="w">
</span><span class="c1"># In each case, we use cv.glmnet to pick our lambda value using cross-validation</span><span class="w">
</span><span class="c1"># using nfolds folds for cross-validation</span><span class="w">
</span><span class="c1"># Note that alpha = 1 picks LASSO</span><span class="w">
</span><span class="n">cv.lasso</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="c1"># We might want to see how the choice of lambda relates to out-of-sample error with a plot</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">cv.lasso</span><span class="p">)</span><span class="w">
</span><span class="c1"># After doing CV, we commonly pick the lambda.min for lambda, </span><span class="w">
</span><span class="c1"># which is the lambda that minimizes out-of-sample error</span><span class="w">
</span><span class="c1"># or lambda.1se, which is one standard error above lambda.min,</span><span class="w">
</span><span class="c1"># which penalizes more harshly. The choice depends on context.</span><span class="w">
</span><span class="n">lasso.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.lasso</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">
</span><span class="c1"># coefficients are shown in the beta element. . means LASSO dropped it</span><span class="w">
</span><span class="n">lasso.model</span><span class="o">$</span><span class="n">beta</span><span class="w">

</span><span class="c1"># Running Ridge, or mixing the two with elastic net, simply means picking</span><span class="w">
</span><span class="c1"># alpha = 0 (Ridge), or 0 &lt; alpha &lt; 1 (Elastic Net)</span><span class="w">
</span><span class="n">cv.ridge</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">
</span><span class="n">ridge.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.ridge</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">

</span><span class="n">cv.elasticnet</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.5</span><span class="p">)</span><span class="w">
</span><span class="n">elasticnet.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.5</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.elasticnet</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
      <h2 id="stata">
          <a href="#stata" aria-labelledby="stata" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Stata
      </h2>
<p>Penalized regression is one of the few machine learning algorithms that Stata does natively. This requires Stata 16. If you do not have Stata 16, you can alternately perform some forms of penalized regression by installing the <strong>lars</strong> package using <strong>ssc install lars</strong>.</p>
<div class="language-stata highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">* Use NLSY-W data
</span><span class="err">sysuse</span> <span class="err">nlsw88.dta,</span> <span class="err">clear
</span><span class="c1">
* Construct all squared and interaction terms by loop so we don't have to specify them all
* by hand in the regression function
</span><span class="err">local</span> <span class="err">numeric_vars</span> <span class="o">=</span> <span class="s2">"age grade hours ttl_exp tenure"</span><span class="err">
local</span> <span class="err">factor_vars</span> <span class="o">=</span> <span class="s2">"race married never_married collgrad south smsa c_city industry occupation union"</span><span class="err">
</span><span class="c1">
* Add all squares
</span><span class="err">foreach</span> <span class="err">x</span> <span class="err">in</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">{
</span>	<span class="err">g</span> <span class="err">sq_</span><span class="p">`</span><span class="si">x' = `x</span><span class="p">'</span><span class="o">^</span><span class="err">2
}
</span><span class="c1">
* Turn all factors into dummies so we can standardize them
</span><span class="err">local</span> <span class="err">faccount</span> <span class="o">=</span> <span class="err">1
local</span> <span class="err">dummy_vars</span> <span class="o">=</span> <span class="s2">""</span><span class="err">
foreach</span> <span class="err">x</span> <span class="err">in</span> <span class="p">`</span><span class="si">factor_vars</span><span class="p">'</span> <span class="err">{
</span>	<span class="err">xi</span> <span class="err">i.</span><span class="p">`</span><span class="si">x', pre(f`count</span><span class="p">'</span><span class="err">_)
</span>	<span class="err">local</span> <span class="err">count</span> <span class="o">=</span> <span class="p">`</span><span class="si">count</span><span class="p">'</span> <span class="o">+</span> <span class="err">1
}
</span><span class="c1">
* Add all numeric-numeric interactions; these are easy
* factor interactions would need a more thorough loop
</span><span class="err">forvalues</span> <span class="err">i</span> <span class="o">=</span> <span class="err">1(1)5</span> <span class="err">{
</span>	<span class="err">local</span> <span class="err">next_i</span> <span class="o">=</span> <span class="p">`</span><span class="si">i</span><span class="p">'</span><span class="o">+</span><span class="err">1
</span>	<span class="err">forvalues</span> <span class="err">j</span> <span class="o">=</span> <span class="p">`</span><span class="si">next_i</span><span class="p">'</span><span class="err">(1)5</span> <span class="err">{
</span>		<span class="err">local</span> <span class="err">namei</span> <span class="o">=</span> <span class="err">word(</span><span class="s2">"`numeric_vars'"</span><span class="err">,</span><span class="p">`</span><span class="si">i</span><span class="p">'</span><span class="err">)
</span>		<span class="err">local</span> <span class="err">namej</span> <span class="o">=</span> <span class="err">word(</span><span class="s2">"`numeric_vars'"</span><span class="err">,</span><span class="p">`</span><span class="si">j</span><span class="p">'</span><span class="err">)
</span>		<span class="err">g</span> <span class="err">interact_</span><span class="p">`</span><span class="si">i'_`j' = `namei'*`namej</span><span class="p">'</span><span class="err">
</span>	<span class="err">}
}
</span><span class="c1">
* Standardize everything
</span><span class="err">foreach</span> <span class="err">var</span> <span class="err">of</span> <span class="err">varlist</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span> <span class="err">{
</span>	<span class="err">qui</span> <span class="err">summ</span> <span class="p">`</span><span class="si">var</span><span class="p">'</span><span class="err">
</span>	<span class="err">qui</span> <span class="err">replace</span> <span class="p">`</span><span class="si">var' = (`var</span><span class="p">'</span> <span class="o">-</span> <span class="err">r(mean))/r(sd)
}
</span><span class="c1">
* Use the lasso command to run LASSO
* using sel(cv) to select lambda using cross-validation
* we specify a linear model here, but logit/probit/poisson would work
</span><span class="err">lasso</span> <span class="err">linear</span> <span class="err">wage</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span><span class="err">,</span> <span class="err">sel(cv)
</span><span class="c1">* get list of included coefficients
</span><span class="err">lassocoef
</span><span class="c1">
* We can use elasticnet to run Elastic Net
* By default, alpha will be selected by cross-validation as well
</span><span class="err">elasticnet</span> <span class="err">linear</span> <span class="err">wage</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span><span class="err">,</span> <span class="err">sel(cv)
</span></code></pre></div></div>
          <hr>
          <footer>
              <div class="d-flex mt-2">
                  <p class="text-small text-grey-dk-000 mb-0">
                    <a href="https://github.com/lost-stats/lost-stats.github.io/edit/source/Machine_Learning/penalized_regression.md" id="edit-this-page">Edit this page on GitHub.</a>
                  </p>
              </div>
          </footer>
      </div>
    </div>
      <div class="search-overlay"></div>
  </div>
</body>
</html>
